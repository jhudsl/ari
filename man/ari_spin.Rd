% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ari_spin.R
\name{ari_spin}
\alias{ari_spin}
\alias{have_polly}
\title{Generate video from images and text}
\usage{
ari_spin(
  images,
  paragraphs,
  output,
  tts_engine = text2speech::tts,
  tts_engine_args = coqui_args(),
  tts_engine_auth = text2speech::tts_auth,
  subtitles = FALSE,
  duration = NULL,
  key_or_json_file = NULL
)

have_polly()
}
\arguments{
\item{images}{A vector of paths to images.}

\item{paragraphs}{A vector strings that will be spoken by Amazon Polly.}

\item{output}{A path to the video file which will be created.}

\item{tts_engine}{The desired engine for converting text-to-speech}

\item{tts_engine_args}{List of parameters provided to the designated text-to-speech engine}

\item{tts_engine_auth}{Authentication required for the designated text-to-speech engine}

\item{subtitles}{Should a \code{.srt} file be created with subtitles? The
default value is \code{FALSE}. If \code{TRUE} then a file with the same name
as the \code{output} argument will be created, but with the file extension
\code{.srt}.}

\item{duration}{a vector of numeric durations for each audio
track.  See \code{\link{pad_wav}}}

\item{key_or_json_file}{access key or JSON file to pass to
\code{\link{tts_auth}} for authorization}
}
\value{
The output from \code{\link{ari_stitch}}
}
\description{
Given equal length vectors of paths to images (preferably \code{.jpg}s
or \code{.png}s) and strings which will be
synthesized by a text-to-speech engine, this function creates an
\code{.mp4} video file where each image is shown with
its corresponding narration. This function uses \code{\link{ari_stitch}} to
create the video.
}
\examples{
\dontrun{

slides <- system.file("test", c("mab2.png", "mab1.png"),
  package = "ari"
)
sentences <- c(
  "Welcome to my very interesting lecture.",
  "Here are some fantastic equations I came up with."
)
ari_spin(slides, sentences, output = "test.mp4",
          tts_engine = text2speech::tts,
         tts_engine_args = coqui_args(model_name = "tacotron2-DDC_ph",
                                      vocoder_name = "ljspeech/univnet"),
         tts_engine_auth = text2speech::tts_auth)

}

}
